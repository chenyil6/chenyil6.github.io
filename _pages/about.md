---
permalink: /
title: "About me - Huiyi Chen, ÈôàÊÖß‰ª™"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Second-year Master student at [Southeast University](https://www.seu.edu.cn/), advised by Prof. [Xu Yang](https://yangxuntu.github.io/). 

I‚Äôm currently looking for PhD position start from 2026 fall. If you are interested, please feel free to contact me. Here is my [resume](https://chenyil6.github.io/files/Huiyi_Chen_CV_new.pdf).

My research interests lie at:

* In-context learning (ICL)
* Large vision-language model (LVLM)
* Multimodal Retrieval-Augmented Generation (MRAG)

## üéì Education

Southeast University , *09/2023 - present*

* Mphil. in Artificial Intelligence. Advisor: [Xu Yang](https://yangxuntu.github.io/)


Nanchang Hangkong University , *09/2019 - 06/2023*

* B.S. in Network Engineering.
  

## üìù Publications and Preprints
(* Refers to the authors having the equal contribution, and should be considered as co-first authors.)


<div style="display: flex; gap: 20px; margin-bottom: 2em; align-items: flex-start;">
  <!-- Á∫ØÂõæÁâáÂ±ïÁ§∫Âå∫ÔºàÊó†ÊñáÂ≠óÔºâ -->
  <div style="flex: 0 0 220px;  height: 160px; border-radius: 4px; border:1px;solid #f0f0f0;">
    <img src="/images/cvpr2024.jpg" 
         style="width:100%;  height: 100%; ">
  </div>

  <!-- Âè≥‰æßËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    
    <div style="margin-bottom: 10px; font-size: 1.1em;">
  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Li_How_to_Configure_Good_In-Context_Sequence_for_Visual_Question_Answering_CVPR_2024_paper.pdf" 
     style="font-weight: 600; text-decoration: none; ">
    How to Configure Good In-Context Sequence for Visual Question Answering
  </a>
    </div>

    <div style="font-weight: normal; color: #333; margin-bottom: 30px; ">
        Li Li<sup>*</sup>, Jiawei Peng<sup>*</sup>, <strong style="font-weight: 600;">Huiyi Chen</strong><sup>*</sup>, Chongyang Gao, Xu Yang
    </div>

    <div style="color: #333; font-size: 0.9em;">
      CVPR 2024 (Poster) | 
      <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Li_How_to_Configure_Good_In-Context_Sequence_for_Visual_Question_Answering_CVPR_2024_paper.pdf" >PDF</a> | 
      <a href="https://github.com/GaryJiajia/OFv2_ICL_VQA">Code</a> 
    </div>

  </div>
</div>

<div style="display: flex; gap: 20px; margin-bottom: 2em; align-items: flex-start;">
  <!-- Á∫ØÂõæÁâáÂ±ïÁ§∫Âå∫ÔºàÊó†ÊñáÂ≠óÔºâ -->
  <div style="flex: 0 0 220px;  height: 160px; border-radius: 4px; border:1px; solid #f0f0f0;">
    <img src="/images/coreset.jpg" 
         style="width:100%;   height: 100%;">
  </div>

  <!-- Âè≥‰æßËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    
    <div style="margin-bottom: 10px; font-size: 1.1em;">
  <a href="https://arxiv.org/pdf/2504.14200" 
     style="font-weight: 600; text-decoration: none; ">
    Enhancing Multimodal In-Context Learning for Image Classification through Coreset Optimization
  </a>
    </div>

    <div style="font-weight: normal; color: #333;margin-bottom: 30px;">
        <strong style="font-weight: 600;">Huiyi Chen</strong>, Jiawei Peng, Kaihua Tang, Xin Geng, Xu Yang
    </div>

    
    <div style="color: #333;font-size: 0.9em;">
     ACM MM 2025 (Oral) |  
      <a href="https://arxiv.org/pdf/2504.14200">PDF</a> | 
      <a href="https://github.com/chenyil6/KeCO_Coreset_Optimization">Code</a> 
    </div>

  </div>
</div>

<div style="display: flex; gap: 20px; margin-bottom: 2em; align-items: flex-start;">
  <!-- Á∫ØÂõæÁâáÂ±ïÁ§∫Âå∫ÔºàÊó†ÊñáÂ≠óÔºâ -->
  <div style="flex: 0 0 220px;  height: 160px; border-radius: 4px; border:1px; solid #f0f0f0;">
    <img src="/images/MVI-Bench.png" 
         style="width:100%;   height: 100%;">
  </div>

  <!-- Âè≥‰æßËÆ∫Êñá‰ø°ÊÅØ -->
  <div style="flex: 1;">
    
    <div style="margin-bottom: 10px; font-size: 1.1em;">
  <a href="https://arxiv.org/pdf/2504.14200" 
     style="font-weight: 600; text-decoration: none; ">
    MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to  Misleading Visual Inputs in LVLMs
  </a>
    </div>

    <div style="font-weight: normal; color: #333;margin-bottom: 30px;">
        <strong style="font-weight: 600;">Huiyi Chen</strong>, Jiawei Peng, Dehai Min, Changchang Sun, Kaijie Chen, Yan Yan, Xu Yang, Lu Cheng
    </div>

    
    <div style="color: #333;font-size: 0.9em;">
     Preprinted |  
      <a href="https://arxiv.org/pdf/2511.14159">PDF</a> |  
      <a href="https://github.com/chenyil6/MVI-Bench">Code</a> 
    </div>

  </div>
</div>



## üß© Hobbies & Interests‚Äã

In my free time, I enjoy reading, practicing digital art with Procreate, and watching films.

* Books: I am a huge fan of ‚ÄãFredrik Backman‚Äôs works, especially *Britt-Marie Was Here*. The story of Mrs. Britt-Marie‚Äîa once-invisible homemaker who finally decides to drive alone to Paris, constantly encourages me. It inspires me to be 'the kind of person who jumps from the rock into the sea', reminding me that it's never too late to start a new life.

* Films: I am a super fan of Disney & Pixar, having watched almost every one of their classic movies, as well as their behind-the-scenes documentaries. My favorites include *Turning Red*, *Soul*, and *Inside Out* . There's a line from *Turning Red* that particularly moved me, when Meimei's mother tells her: "The farther you go, the prouder I will be."
