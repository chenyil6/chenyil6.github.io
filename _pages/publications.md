---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}

## Publications 
(* Refers to the authors having the equal contribution, and should be considered as co-first authors.)


### 2025
* **Huiyi Chen**, Jiawei Peng, Kaihua Tang, Xin Geng, Xu Yang. Enhancing Multimodal In-Context Learning for Image Classification through Coreset Optimization (Arxiv).

The paper proposes a novel coreset construction framework, KeCO, for image classification tasks, aimed at enhancing the in-context learning capabilities of Large Vision-Language Models. KeCO leverages untapped data from the support set to aggregate category-relevant information into the coreset via feature-level updates. Notably, KeCO achieves strong performance in a simulated online scenario, demonstrating its practical applicability.


### 2024

* Li Li\*, Jiawei Peng\*, **Huiyi Chen**\*, Chongyang Gao, and Xu Yang. [How to Configure Good In-Context Sequence for Visual Question Answering](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_How_to_Configure_Good_In-Context_Sequence_for_Visual_Question_Answering_CVPR_2024_paper.pdf) (CVPR 2024, Poster)

The paper explores how to configure effective in-context sequences for Visual Question Answering (VQA) tasks to enhance the in-context learning (ICL) capabilities of Large Visual Language Models (LVLM). The paper elaborates on the role of different in-context configuration in LVLM and designs new configuration methods, providing valuable insights for optimizing LVLMâ€™s ICL performance in VQA tasks.
